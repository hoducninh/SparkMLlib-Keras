{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Mllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The outline of this notebook__:\n",
    "\n",
    "I. Hadoop ecosystem and Spark \n",
    "\n",
    "II. Recommendation System using Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop ecosystem and Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to understand Hadoop and its ecosystem before dive deep into Spark. The Hadoop ecosystem is demonstrated as the below figure.\n",
    "\n",
    "![hadoop-ecosystem](spark-imgs/Hadoop-Ecosystem.jpg)\n",
    "\n",
    "A very goods articles about Hadoop ecosystem could be found [here](https://data-flair.training/blogs/hadoop-ecosystem-components/). It is worth reading for beginners. \n",
    "\n",
    "We do not see Spark in the above ecosystem. However, Apache Spark was created as an alternative to the implementation of MapReduce in Hadoop to gain efficiencies measured in orders of magnitude. \n",
    "\n",
    "The Spark core is complemented by a set of powerful, higher-level libraries which can be seamlessly used in the same application. These libraries currently include SparkSQL, Spark Streaming, MLlib (for machine learning), GraphX and SparkR, each of which is further detailed in [this article](https://www.toptal.com/spark/introduction-to-apache-spark).\n",
    "\n",
    "![spark-components](spark-imgs/Apache-Spark-Components.jpg)\n",
    "\n",
    "Additional key features of Spark include:\n",
    "\n",
    "- Currently provides APIs in Scala, Java, Python and R.\n",
    "- Integrates well with the Hadoop ecosystem and data sources (HDFS, Amazon S3, Hive, HBase, Cassandra, etc.).\n",
    "- Can run on clusters managed by Hadoop YARN or Apache Mesos, and can also run standalone.\n",
    "\n",
    "There are many concepts to learn about Hadoop and Spark. However, we focus on Spark MLlib in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System using Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Recommendation Engines\n",
    "\n",
    "- Content-Based\n",
    "- Collaborative Filtering\n",
    "- Matrix Fatorization\n",
    "- Deep Learning \n",
    "\n",
    "Spark MLlib library for Machine Learning use Alternating Least Squares for Collaborative Filtering implementation. \n",
    "\n",
    "With Collaborative filtering we make predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption is that if a user A has the same opinion as a user B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a user chosen randomly.\n",
    "\n",
    "The image below (from Wikipedia) shows an example of collaborative filtering. At first, people rate different items (like videos, images, games). Then, the system makes predictions about a user's rating for an item not rated yet. The new predictions are built upon the existing ratings of other users with similar ratings with the active user. In the image, the system predicts that the user will not like the video.\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif />\n",
    "\n",
    "Let's see this all in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and Imports\n",
    "\n",
    "To start, create a `SparkSession` then import the recommendation system and evaluation algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('recommender').getOrCreate()\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('movilen-dataset/movies_ratings_df.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['user_id', 'movie_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+\n",
      "|summary|          user_id|          movie_id|            rating|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "|  count|          1000209|           1000209|           1000209|\n",
      "|   mean|3024.512347919285|1865.5398981612843| 3.581564453029317|\n",
      "| stddev|1728.412694899974| 1096.040689457246|1.1171018453732597|\n",
      "|    min|                1|                 1|                 1|\n",
      "|    max|             6040|              3952|                 5|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model and Making Predictions\n",
    "\n",
    "To train the model and make predictions, we need a training and an evaluation set. Here the training set is 80% of randomly selected samples and the rest are for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5, regParam=0.01, userCol='user_id', itemCol='movie_id', ratingCol='rating')\n",
    "\n",
    "model = als.fit(training)\n",
    "\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold Start Predictions\n",
    "\n",
    "When there are cold start users or items to make predictions on (ones not available in the model) the predictions produce NaNs as shown in the summary below. This also causes evaluation with the mean squared error to produce a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+----------+\n",
      "|summary|           user_id|          movie_id|            rating|prediction|\n",
      "+-------+------------------+------------------+------------------+----------+\n",
      "|  count|            199488|            199488|            199488|    199488|\n",
      "|   mean|3024.0575272698106|1867.3710248235484| 3.584807106191851|       NaN|\n",
      "| stddev|1732.0740352907983|1097.9873513030911|1.1175103643076427|       NaN|\n",
      "|    min|                 1|                 1|                 1|-7.5180225|\n",
      "|    max|              6040|              3952|                 5|       NaN|\n",
      "+-------+------------------+------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, the rows can be dropped with `predictions.na.drop()`. A more streamlined way is to add the `coldStartStrategy=\"drop\"` as a model parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|           user_id|          movie_id|            rating|        prediction|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|            199456|            199456|            199456|            199456|\n",
      "|   mean| 3024.089002085673|1867.3020064575646| 3.584976135087438|3.5557930856596407|\n",
      "| stddev|1732.0920121091578|1097.9597800874194|1.1174216829378705|0.8012721307528049|\n",
      "|    min|                 1|                 1|                 1|        -7.5180225|\n",
      "|    max|              6040|              3952|                 5|          8.444759|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.na.drop()\n",
    "predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating|prediction|\n",
      "+-------+--------+------+----------+\n",
      "|    673|     148|     5| 3.3422542|\n",
      "|   5333|     148|     3| 2.2194846|\n",
      "|    482|     148|     2| 2.8373501|\n",
      "|   4169|     463|     2|  2.827493|\n",
      "|     26|     463|     3| 3.9142697|\n",
      "|   3328|     463|     4|  3.803137|\n",
      "|   3032|     463|     4| 4.3333335|\n",
      "|    202|     463|     3|  2.901569|\n",
      "|    721|     463|     4| 3.4054084|\n",
      "|   1980|     463|     2| 2.4942303|\n",
      "|    392|     471|     4| 3.7530158|\n",
      "|   5614|     471|     5| 4.0558205|\n",
      "|   1699|     471|     5|    3.8143|\n",
      "|   3704|     471|     5|  4.530177|\n",
      "|   5345|     471|     4| 4.2094007|\n",
      "|    588|     471|     4|  4.133444|\n",
      "|     78|     471|     4| 3.7239463|\n",
      "|   4172|     471|     3| 3.7793446|\n",
      "|   3685|     471|     5| 4.5230346|\n",
      "|   4482|     471|     4| 3.5656407|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "0.8927010502873391\n",
      "Root-mean-square error = 0.8927010502873391\n"
     ]
    }
   ],
   "source": [
    "predictions.show()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(str(rmse))\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE described our error in terms of the stars rating column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have the model, how would we actually supply a recommendation to a user?\n",
    "\n",
    "The same way we did with the test data! For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_user = test.filter(test['user_id']==6).select(['movie_id','user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|movie_id|user_id|\n",
      "+--------+-------+\n",
      "|      17|      6|\n",
      "|      34|      6|\n",
      "|     296|      6|\n",
      "|     595|      6|\n",
      "|     920|      6|\n",
      "|    1101|      6|\n",
      "|    1688|      6|\n",
      "|    1806|      6|\n",
      "|    1947|      6|\n",
      "|    2006|      6|\n",
      "|    2082|      6|\n",
      "|    2100|      6|\n",
      "|    2506|      6|\n",
      "|    3524|      6|\n",
      "|    3682|      6|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User had 14 ratings in the test data set \n",
    "# Realistically this should be some sort of hold out set!\n",
    "single_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomendations = model.transform(single_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+\n",
      "|movie_id|user_id|prediction|\n",
      "+--------+-------+----------+\n",
      "|    2506|      6|  4.853216|\n",
      "|     920|      6| 4.7831426|\n",
      "|    1688|      6| 4.6620526|\n",
      "|    1101|      6| 4.5707235|\n",
      "|    1947|      6|  4.472553|\n",
      "|    2006|      6| 4.2910757|\n",
      "|     595|      6| 4.1513247|\n",
      "|    2082|      6| 4.1028743|\n",
      "|      17|      6| 3.8527308|\n",
      "|    3524|      6| 3.6430182|\n",
      "|    2100|      6| 3.5029235|\n",
      "|    3682|      6| 3.5004683|\n",
      "|      34|      6| 3.2677448|\n",
      "|    1806|      6| 3.2543948|\n",
      "|     296|      6| 1.6700982|\n",
      "+--------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reccomendations.orderBy('prediction',ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
